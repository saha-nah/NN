Dataset:
https://www.kaggle.com/datasets/sherinclaudia/movielens

import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
#Loading in the movies dataset
movies = pd.read_csv('/content/drive/MyDrive/datasets/movies.dat', sep = '::', header = None, 
engine = 'python', encoding = 'latin-1')
#Loading in the ratings dataset
Users = pd.read_csv('/content/drive/MyDrive/datasets/users.dat', sep = '::', header = None, 
engine = 'python', encoding = 'latin-1')
ratings = pd.read_csv('/content/drive/MyDrive/datasets/ratings.dat', sep = '::', header = None, 
engine = 'python', encoding = 'latin-1')
user_rating_df = ratings.pivot(index='UserID', columns='MovieID', values='Rating')
ratings=ratings.drop('Timestamp',axis=1)
ratings.head()
norm_user_rating_df = user_rating_df.fillna(0) / 5.0
trX = norm_user_rating_df.values
trX[0:5]
hiddenUnits = 20
visibleUnits = len(user_rating_df.columns)
vb = tf.Variable(tf.zeros([visibleUnits]), tf.float32) 
hb = tf.Variable(tf.zeros([hiddenUnits]), tf.float32) 
W = tf.Variable(tf.zeros([visibleUnits, hiddenUnits]), tf.float32)
v0 = tf.zeros([visibleUnits], tf.float32)
#testing to see if the matrix product works
tf.matmul([v0], W)
def hidden_layer(v0_state, W, hb):
 h0_prob = tf.nn.sigmoid(tf.matmul([v0_state], W) + hb) #probabilities of the hidden units
 h0_state = tf.nn.relu(tf.sign(h0_prob - tf.random.uniform(tf.shape(h0_prob)))) 
#sample_h_given_X
 return h0_state
#printing output of zeros input
h0 = hidden_layer(v0, W, hb)
print("first 15 hidden states: ", h0[0][0:15])
def reconstructed_output(h0_state, W, vb):
 v1_prob = tf.nn.sigmoid(tf.matmul(h0_state, tf.transpose(W)) + vb) 
 v1_state = tf.nn.relu(tf.sign(v1_prob - tf.random.uniform(tf.shape(v1_prob)))) 
#sample_v_given_h
 return v1_state[0]
v1 = reconstructed_output(h0, W, vb)
print("hidden state shape: ", h0.shape)
print("v0 state shape: ", v0.shape)
print("v1 state shape: ", v1.shape)
def error(v0_state, v1_state):
 return tf.reduce_mean(tf.square(v0_state - v1_state))
err = tf.reduce_mean(tf.square(v0 - v1))
print("error" , err.numpy())
epochs = 5
batchsize = 500
errors = []
weights = []
K=1
alpha = 0.1
#creating datasets
train_ds = \tf.data.Dataset.from_tensor_slices((np.float32(trX))).batch(batchsize)
v0_state=v0
for epoch in range(epochs):
 batch_number = 0
 for batch_x in train_ds:
 for i_sample in range(len(batch_x)): 
 for k in range(K):
 v0_state = batch_x[i_sample]
 h0_state = hidden_layer(v0_state, W, hb)
 v1_state = reconstructed_output(h0_state, W, vb)
 h1_state = hidden_layer(v1_state, W, hb)
 delta_W = tf.matmul(tf.transpose([v0_state]), h0_state) -
tf.matmul(tf.transpose([v1_state]), h1_state)
 W = W + alpha * delta_W
 vb = vb + alpha * tf.reduce_mean(v0_state - v1_state, 0)
 hb = hb + alpha * tf.reduce_mean(h0_state - h1_state, 0) 
 v0_state = v1_state
 if i_sample == len(batch_x)-1:
 err = error(batch_x[i_sample], v1_state)
 errors.append(err)
 weights.append(W)
 print ( 'Epoch: %d' % (epoch + 1), 
 "batch #: %i " % batch_number, "of %i" % (len(trX)/batchsize), 
 "sample #: %i" % i_sample,
 'reconstruction error: %f' % err)
 batch_number += 1
plt.plot(errors)
plt.ylabel('Error')
plt.xlabel('Epoch')
plt.show()
mock_user_id = 215
#Selecting the input user
inputUser = trX[mock_user_id-1].reshape(1, -1)
inputUser = tf.convert_to_tensor(trX[mock_user_id-1],"float32")
v0 = inputUser
print(v0)
v0.shape
v0test = tf.zeros([visibleUnits], tf.float32)
v0test.shape
#Feeding in the user and reconstructing the input
hh0 = tf.nn.sigmoid(tf.matmul([v0], W) + hb)
vv1 = tf.nn.sigmoid(tf.matmul(hh0, tf.transpose(W)) + vb)
rec = vv1
tf.maximum(rec,1)
for i in vv1:
 print(i)
scored_movies_df_mock = movies[movies['MovieID'].isin(user_rating_df.columns)]
scored_movies_df_mock = scored_movies_df_mock.assign(RecommendationScore = rec[0])
scored_movies_df_mock.sort_values(["RecommendationScore"], ascending=False).head(20)
movies_df_mock = ratings[ratings['UserID'] == mock_user_id]
movies_df_mock.head()
#Merging movies_df with ratings_df by MovieID
merged_df_mock = scored_movies_df_mock.merge(movies_df_mock, on='MovieID', 
how='outer')
merged_df_mock['UserID']=merged_df_mock['UserID'].astype(pd.Int64Dtype()
merged_df_mock.sort_values(["RecommendationScore"], ascending=False).head(10)
